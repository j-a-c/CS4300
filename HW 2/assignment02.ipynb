{
 "metadata": {
  "name": "",
  "signature": "sha256:37b5072caef18514c7a076e9758058563971e3b990050c074a2befc183a63e54"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Assignment 02: \"Search your transcripts. You will know it to be true.\"\n",
      "## CS/INFO 4300 Language and Information\n",
      "\n",
      "**Due Tuesday, February 24 at 5pm**\n",
      "\n",
      "This assignment can be completed in groups of 1 to 2 (see description).\n",
      "\n",
      "In this assignment we will explore the tradeoffs of information retrieval systems by finding newspaper quotes from \"Keeping Up With The Kardashians\".\n",
      "\n",
      "**Guidelines**\n",
      "\n",
      "For code completion tasks, just type your code after the comment marking the place.  For questions, use as many notebook cells as needed to compute intermediate stuff. All floating point values should be printed with 2 decimal places precision.\n",
      "\n",
      "You are strongly encouraged to write sensible **test cases** for your code.\n",
      "\n",
      "# Setup\n",
      "\n",
      "Tabloids have been going crazy over our stars.  The press took some  quotes from the show, including:\n",
      "       \n",
      " - *\"It's like a bunch of people running around talking about nothing.\"*\n",
      " - *\"Never say to a famous person that this possible endorsment would bring 'er to the spot light.\"*\n",
      " - *\"Your yapping is making my head ache!\"*\n",
      " - *\"I'm going to Maryland, did I tell you?\"*\n",
      " \n",
      "We need to find out who said each of these, and in which episode. But since we're information scientists, that's not enough. We want to build an efficient search engine for retrieving where such quotes come from in the future.\n",
      "\n",
      "What makes this difficult is that journalists often modify the quotes, so exact matching will not always work."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "import numpy as np\n",
      "from collections import defaultdict\n",
      "from nltk.tokenize import TreebankWordTokenizer\n",
      "import Levenshtein  # package python-Levenshtein"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "queries = [u\"It's like a bunch of people running around talking about nothing.\",\n",
      "           u\"Never say to a famous person that this possible endorsment would bring 'er to the spot light.\",\n",
      "           u\"Your yapping is making my head ache!\",\n",
      "           u\"I'm going to Maryland, did I tell you?\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Load the data\n",
      "\n",
      "Load the transcripts provided in the `kardashian-transcripts.json` file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "with open(\"kardashian-transcripts.json\", \"rb\") as f:\n",
      "    transcripts = json.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Reorganize the data\n",
      "\n",
      "For this assignment, we'll consider documents to be individual message lines. The provided transcripts are grouped differently. Reorganize the data as a list of messages, where the messages are dictionary structures as provided."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flat_msgs = [m for transcript in transcripts for m in transcript]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Data structure test\n",
      "msg = flat_msgs[0]\n",
      "print(msg)\n",
      "print('===')\n",
      "print(msg['text'])\n",
      "print('===')\n",
      "for tok in msg['toks']:\n",
      "    print(tok)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'toks': [u'you', u'do', u\"n't\", u'have', u'your', u'own', u'credit', u'card', u'?'], u'timestamp': u'00:00:23', u'episode_title': u'Keeping Up With the Kardashians - Shape Up or Ship Out', u'transcript_id': u'kardashians/153890', u'speaker': u'KHLOE', u'text': u\"You don't have your own credit card?\"}\n",
        "===\n",
        "You don't have your own credit card?\n",
        "===\n",
        "you\n",
        "do\n",
        "n't\n",
        "have\n",
        "your\n",
        "own\n",
        "credit\n",
        "card\n",
        "?\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Searching the collection\n",
      "\n",
      "The first and easiest thing to try is to directly compare the newspaper quote to the transcript strings.  If the press just copy-pasted from the transcript website, this might work.\n",
      "\n",
      "## Find all messages that include the given quotes exactly.\n",
      "\n",
      "Print the episode title, speaker name and full message, for all messages that exactly contain a given quote.\n",
      "\n",
      "Write this as a function `verbatim_search` and run the function for each of the 4 quotes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Q1 Write a function `verbatim_search` that looks for exact matches of a query in each message.\n",
      "\n",
      "Use `in`: `'efg' in 'cdefgh'` is `True`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def verbatim_search(query, msgs):\n",
      "    \"\"\" Verbatim search\n",
      "    \n",
      "    Arguments\n",
      "    =========\n",
      "    \n",
      "    query: string,\n",
      "        The query we are looking for.\n",
      "        \n",
      "    msgs: list of dicts,\n",
      "        Each message in this list has a 'text' field with\n",
      "        the raw document.\n",
      "    \n",
      "    Returns\n",
      "    =======\n",
      "    result: list of messages\n",
      "        All messages that exactly contain the query string.\n",
      "    \n",
      "    \"\"\"\n",
      "    \n",
      "    matching_msgs = []\n",
      "    for msg in msgs:\n",
      "        if query in msg['text']:\n",
      "            matching_msgs.append(msg)\n",
      "            \n",
      "    return matching_msgs\n",
      "\n",
      "\n",
      "def verbatim_search_test1():\n",
      "    msg1 = {'text':'cdefg'}\n",
      "    msg2 = {'text':'cdfg'}\n",
      "    msg3 = {'text':'asdf?'}\n",
      "    msgs = [msg1, msg2, msg3]\n",
      "    \n",
      "    matching_queries = verbatim_search('efg', msgs)\n",
      "    \n",
      "    assert(len(matching_queries) == 1)\n",
      "    assert(matching_queries[0]['text'] == 'cdefg')\n",
      "    \n",
      "    print('verbatim_search_test1 successful')\n",
      "    \n",
      "verbatim_search_test1()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "verbatim_search_test1 successful\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for query in queries:\n",
      "    print(query)\n",
      "    print(\"===\")\n",
      "    for msg in verbatim_search(query, flat_msgs):\n",
      "        print(\"{}: {}\\n\\t({})\\n\".format(msg['speaker'].encode('utf-8'),\n",
      "                                        msg['text'].encode('utf-8'),\n",
      "                                        msg['episode_title'].encode('utf-8')))\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "It's like a bunch of people running around talking about nothing.\n",
        "===\n",
        "BRUCE: It's like a bunch of people running around talking about nothing.\n",
        "\t(Keeping Up With the Kardashians - Kourt's First Cover)\n",
        "\n",
        "\n",
        "Never say to a famous person that this possible endorsment would bring 'er to the spot light.\n",
        "===\n",
        "\n",
        "Your yapping is making my head ache!\n",
        "===\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I'm going to Maryland, did I tell you?\n",
        "===\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Find the most similar messages (cosine similarity)\n",
      "\n",
      "We will use an **inverted index** for efficiency. This is a sparse term-centered representation that allows us to quickly find all documents that contain a given term.\n",
      "\n",
      "### Q2 Write a function to construct the index.\n",
      "\n",
      "As in class, the index is a key-value structure where the keys are terms and the values are lists of *postings*. In this case, like in class, we record the documents a term occurs in as well as the **count** of that term in that document."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_inverted_index(msgs):\n",
      "    \"\"\" Builds an inverted index from the messages.\n",
      "    \n",
      "    Arguments\n",
      "    =========\n",
      "    \n",
      "    msgs: list of dicts.\n",
      "        Each message in this list already has a 'toks'\n",
      "        field that contains the tokenized message.\n",
      "    \n",
      "    Returns\n",
      "    =======\n",
      "    \n",
      "    index: dict\n",
      "        For each term, the index contains a list of\n",
      "        tuples (doc_id, count_of_term_in_doc):\n",
      "        index[term] = [(d1, tf1), (d2, tf2), ...]\n",
      "        \n",
      "    Example\n",
      "    =======\n",
      "    \n",
      "    >> test_idx = build_inverted_index([\n",
      "    ...    {'toks': ['to', 'be', 'or', 'not', 'to', 'be']},\n",
      "    ...    {'toks': ['do', 'be', 'do', 'be', 'do']}])\n",
      "    \n",
      "    >> test_idx['be']\n",
      "    [(0, 2), (1, 2)]\n",
      "    \n",
      "    >> test_idx['not']\n",
      "    [(0, 1)]\n",
      "    \n",
      "    \"\"\"\n",
      "    inverted_index = defaultdict(list)\n",
      "    \n",
      "    next_id = 0\n",
      "    \n",
      "    for msg in msgs:\n",
      "        doc_id = next_id\n",
      "        tokens = msg['toks']\n",
      "        for token in set(tokens):\n",
      "            tok_list = inverted_index[token]\n",
      "            tok_list.append((doc_id, tokens.count(token)))\n",
      "        next_id += 1\n",
      "    \n",
      "    return inverted_index\n",
      "\n",
      "\n",
      "def build_inverted_index_test1():\n",
      "    test_idx = build_inverted_index([\n",
      "         {'toks': ['to', 'be', 'or', 'not', 'to', 'be']},\n",
      "        {'toks': ['do', 'be', 'do', 'be', 'do']}])\n",
      "    \n",
      "    assert(test_idx['be'] == [(0, 2), (1, 2)])\n",
      "    assert(test_idx['not'] == [(0, 1)])\n",
      "    \n",
      "    print('build_inverted_index_test1 successful')\n",
      "    \n",
      "build_inverted_index_test1()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "build_inverted_index_test1 successful\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Q3 Compute IDF *using* the inverted index\n",
      "\n",
      "Write a function `compute_idf` that uses the inverted index to efficiently compute IDF values.\n",
      "\n",
      "Words that occur in a very small number of documents are not useful in many cases, so we ignore them. Use a parameter `min_df`\n",
      "to ignore all terms that occur in strictly fewer than `min_df` documents.\n",
      "\n",
      "Similarly, words that occur in a large *fraction* of the documents don't bring any more information for some tasks. Use a parameter `max_df_ratio` to trim out such words. For example, `max_df_ratio=0.95` means ignore all words that occur in more than 95% of the documents."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%latex\n",
      "\n",
      "$$ IDF(t) = \\log \\left(\\frac{N}{1 + DF(t)} \\right) $$\n",
      "\n",
      "N = total number of docs; \n",
      "\n",
      "$DF(t)$ = number of docs containing $t$."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "\n",
        "$$ IDF(t) = \\log \\left(\\frac{N}{1 + DF(t)} \\right) $$\n",
        "\n",
        "N = total number of docs; \n",
        "\n",
        "$DF(t)$ = number of docs containing $t$."
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Latex at 0xeb1b62c>"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_idf(inv_idx, n_docs, min_df=10, max_df_ratio=0.95):\n",
      "    \"\"\" Compute term IDF values from the inverted index.\n",
      "    \n",
      "    Words that are too frequent or too infrequent get pruned.\n",
      "    \n",
      "    \n",
      "    Arguments\n",
      "    =========\n",
      "    \n",
      "    inv_idx: an inverted index as above\n",
      "    \n",
      "    n_docs: int,\n",
      "        The number of documents.\n",
      "        \n",
      "    min_df: int,\n",
      "        Minimum number of documents a term must occur in.\n",
      "        Less frequent words get ignored.\n",
      "    \n",
      "    max_df_ratio: float,\n",
      "        Maximum ratio of documents a term can occur in.\n",
      "        More frequent words get ignored.\n",
      "    \n",
      "    Returns\n",
      "    =======\n",
      "    \n",
      "    idf: dict\n",
      "        For each term, the dict contains the idf value.\n",
      "        \n",
      "    \"\"\"\n",
      "    idf = defaultdict(int)\n",
      "    \n",
      "    max_cut_off = max_df_ratio * n_docs\n",
      "    \n",
      "    for term in inv_idx:\n",
      "        doc_list = inv_idx[term]\n",
      "        num_docs_with_term = len(doc_list)\n",
      "        \n",
      "        # Apply thresholding\n",
      "        if (num_docs_with_term >= min_df) and (num_docs_with_term <= max_cut_off):\n",
      "            idf[term] = np.log(n_docs / (1.0+num_docs_with_term))\n",
      "            \n",
      "    return idf\n",
      "\n",
      "def compute_idf_test1():\n",
      "    test_idx = build_inverted_index([\n",
      "         {'toks': ['to', 'be', 'or', 'not', 'to', 'be']},\n",
      "        {'toks': ['do', 'be', 'do', 'be', 'do']},\n",
      "        {'toks': ['asdf', 'fsda', 'be']}])\n",
      "    \n",
      "    idf = compute_idf(test_idx, 3, 0, max_df_ratio=0.95)\n",
      "    \n",
      "    assert('be' not in idf)\n",
      "    assert(idf['do'] == np.log(3/2.0))\n",
      "    \n",
      "    print('compute_idf_test1 successful.')\n",
      "    \n",
      "compute_idf_test1()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "compute_idf_test1 successful.\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Q4 Compute the norm of each document using the inverted index"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%latex\n",
      "\n",
      "$$ \\left|\\left| d_j \\right|\\right| = \\sqrt{\\sum_i (tf_{ij} \\cdot idf_i)^2} $$"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "\n",
        "$$ \\left|\\left| d_j \\right|\\right| = \\sqrt{\\sum_i (tf_{ij} \\cdot idf_i)^2} $$"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Latex at 0x106097d90>"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "\n",
      "def compute_doc_norms(index, idf, n_docs):\n",
      "    \"\"\" Precompute the euclidean norm of each document.\n",
      "    \n",
      "    Arguments\n",
      "    =========\n",
      "    \n",
      "    index: the inverted index as above\n",
      "    \n",
      "    idf: dict,\n",
      "        Precomputed idf values for the terms.\n",
      "    \n",
      "    n_docs: int,\n",
      "        The total number of documents.\n",
      "    \n",
      "    Returns\n",
      "    =======\n",
      "    \n",
      "    norms: list of np.array, size: n_docs\n",
      "        norms[i] = the norm of document i.\n",
      "    \"\"\"\n",
      "    \n",
      "    norms = [0.0 for i in range(n_docs)]\n",
      "    \n",
      "    for term in idf:\n",
      "        term_idf = idf[term]\n",
      "        \n",
      "        for doc_freq_pair in index[term]:\n",
      "            doc_id = doc_freq_pair[0]\n",
      "            doc_freq = doc_freq_pair[1]\n",
      "            \n",
      "            norms[doc_id] += (doc_freq * term_idf)**2\n",
      "            \n",
      "    norms = [math.sqrt(i) for i in norms]\n",
      "    return norms\n",
      "\n",
      "\n",
      "def compute_doc_norms_test1():\n",
      "    \n",
      "    test_docs = [\n",
      "         {'toks': ['to', 'be', 'or', 'not', 'to', 'be']},\n",
      "        {'toks': ['do', 'be', 'do', 'be', 'do']},\n",
      "        {'toks': ['asdf', 'fsda', 'be']}]\n",
      "    \n",
      "    n_docs = 3\n",
      "    \n",
      "    test_idx = build_inverted_index(test_docs)\n",
      "    \n",
      "    idf = compute_idf(test_idx, n_docs, 0, max_df_ratio=0.95)\n",
      "    \n",
      "    norms = compute_doc_norms(test_idx, idf, n_docs)\n",
      "    \n",
      "    assert(len(norms) == n_docs)\n",
      "    \n",
      "    doc_2_norm = math.sqrt( (idf['asdf'])**2 + (idf['fsda'])**2 )\n",
      "    assert(norms[2] == doc_2_norm)\n",
      "    \n",
      "    print('compute_doc_norms_test1 successful.')\n",
      "    \n",
      "    \n",
      "compute_doc_norms_test1()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "compute_doc_norms_test1 successful.\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Q5 Find the most similar messages to the quotes.  Write the `search_index` function.\n",
      "\n",
      "Run the search using the code provided. Discuss why it worked, or why it might not have worked, for each query.\n",
      "\n",
      "Use cosine similarity. Assume the weight of any term in the query is 1, and the norm of the query is 1.\n",
      "\n",
      "**Note** Use the `nltk.tokenize.TreebankWordTokenizer` to tokenize the query. The transcripts have already been tokenized this way.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Aside:** Precomputation\n",
      "\n",
      "In many settings, we will need to repeat the same kind of operation many times. Often, part of the input doesn't change.\n",
      "Queries against the Kardashians transcript are like this: we want to run more queries (in the real world we'd want to run a lot of them every second, even) but the data we are searching doesn't change.\n",
      "\n",
      "We could write an `index_search` function with the same signature as `verbatim_search`, taking the `query` and the `msgs` as input, and the function would look like:\n",
      "\n",
      "    def index_search(query, msgs):\n",
      "        inv_idx = build_inverged_index(msgs)\n",
      "        idf = compute_idf(inv_idx, len(msgs))\n",
      "        doc_norms = compute_doc_norms(inv_idx)\n",
      "        # do actual search\n",
      "\n",
      "\n",
      "But notice that the first three lines only depend on the messages. Imagine if we run this a million times with different queries but the same collection of documents: we'd wastefully recompute the index, the IDFs and the norms every time and discard them.  It's a better idea, then, to precompute them just once, and pass them as arguments."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inv_idx = build_inverted_index(flat_msgs)\n",
      "\n",
      "idf = compute_idf(inv_idx, len(flat_msgs),\n",
      "                  min_df=10,\n",
      "                  max_df_ratio=0.1)  # documents are very short so we can use a small value here\n",
      "                                     # examine the actual DF values of common words like \"the\"\n",
      "                                     # to set these values\n",
      "\n",
      "inv_idx = {key: val for key, val in inv_idx.items()\n",
      "           if key in idf}            # prune the terms left out by idf\n",
      "\n",
      "doc_norms = compute_doc_norms(inv_idx, idf, len(flat_msgs))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokenizer = TreebankWordTokenizer()\n",
      "tokenizer.tokenize(\"a more general-purpose tokenizer\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "['a', 'more', 'general-purpose', 'tokenizer']"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def index_search(query, index, idf, doc_norms):\n",
      "    \"\"\" Search the collection of documents for the given query\n",
      "    \n",
      "    Arguments\n",
      "    =========\n",
      "    \n",
      "    query: string,\n",
      "        The query we are looking for.\n",
      "    \n",
      "    index: an inverted index as above\n",
      "    \n",
      "    idf: idf values precomputed as above\n",
      "    \n",
      "    doc_norms: document norms as computed above\n",
      "    \n",
      "    Returns\n",
      "    =======\n",
      "    \n",
      "    results, list of tuples (score, doc_id)\n",
      "        Sorted list of results such that the first element has\n",
      "        the highest score, and `doc_id` points to the document\n",
      "        with the highest score.\n",
      "        \n",
      "    \"\"\"\n",
      "    \n",
      "    query_tokens = set(tokenizer.tokenize(query))\n",
      "    \n",
      "    results = []\n",
      "    \n",
      "    for doc_id, doc_norm in enumerate(doc_norms):\n",
      "        dot_product = 0.0\n",
      "        \n",
      "        for query_tok in query_tokens:\n",
      "            if query_tok in idf:\n",
      "                dot_product += flat_msgs[doc_id]['toks'].count(query_tok)\n",
      "        \n",
      "        doc_score = 0.0\n",
      "        \n",
      "        if doc_norm != 0.0:\n",
      "            doc_score = dot_product / doc_norm\n",
      "        results.append( (doc_score, doc_id) )\n",
      "    \n",
      "    return sorted(results, key=lambda tup: tup[0], reverse = True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for query in queries:\n",
      "    print(\"#\" * len(query))\n",
      "    print(query)\n",
      "    print(\"#\" * len(query))\n",
      "\n",
      "    for score, msg_id in index_search(query, inv_idx, idf, doc_norms)[:10]:\n",
      "        print(\"[{:.2f}] {}: {}\\n\\t({})\".format(\n",
      "            score,\n",
      "            flat_msgs[msg_id]['speaker'].encode('utf-8'),\n",
      "            flat_msgs[msg_id]['text'].encode('utf-8'),\n",
      "            flat_msgs[msg_id]['episode_title'].encode('utf-8'))) \n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#################################################################\n",
        "It's like a bunch of people running around talking about nothing.\n",
        "#################################################################\n",
        "[0.57] BRUCE: It's like a bunch of people running around talking about nothing.\n",
        "\t(Keeping Up With the Kardashians - Kourt's First Cover)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0.38] KRIS: It's, like, unreal.\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "[0.38] KRIS: Like a crack addict.\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "[0.38] BRUCE: I like it.\n",
        "\t(Keeping Up With the Kardashians - Must Love Dogs)\n",
        "[0.38] BRUCE: I like it.\n",
        "\t(Keeping Up With the Kardashians - Must Love Dogs)\n",
        "[0.38] KHLOE: Like masturbation?\n",
        "\t(Keeping Up With the Kardashians - Weekend From Hell)\n",
        "[0.38] KIM: That's, like, a Post-It.\n",
        "\t(Keeping Up With the Kardashians - Baby Blues)\n",
        "[0.38] KRIS: You like that?\n",
        "\t(Keeping Up With the Kardashians - Distance Makes the Heart Grow Fonder)\n",
        "[0.38] KHLOE: Like a turkey.\n",
        "\t(Keeping Up With the Kardashians - Leaving the Nest)\n",
        "[0.38] KHLOE: Like a cat.\n",
        "\t(Keeping Up With the Kardashians - Birthday Suit)\n",
        "\n",
        "#############################################################################################\n",
        "Never say to a famous person that this possible endorsment would bring 'er to the spot light.\n",
        "#############################################################################################\n",
        "[0.39] KHLOE: This.\n",
        "\t(Keeping Up With the Kardashians - All for One and One for Kim)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0.39] KHLOE: You encourage this.\n",
        "\t(Keeping Up With the Kardashians - Kourt Goes A.W.O.L.)\n",
        "[0.39] KRIS: This issogood.\n",
        "\t(Keeping Up With the Kardashians - Kim Becomes a Diva)\n",
        "[0.34] KOURTNEY: I'll bring this and this.\n",
        "\t(Keeping Up With the Kardashians - Weekend From Hell)\n",
        "[0.32] KOURTNEY: I say we load up theb\u00e9b\u00e9;I'll bring this and this.\n",
        "\t(Keeping Up With the Kardashians - Leaving the Nest)\n",
        "[0.28] SIMON: You know, it's like I wouldn't do this to you.\n",
        "\t(Keeping Up With the Kardashians - What's Yours Is Mine)\n",
        "[0.28] SIMON: You know, it's like I wouldn't do this to you.\n",
        "\t(Keeping Up With the Kardashians - What's Yours Is Mine)\n",
        "[0.28] KHLOE: No, you would be like this.\n",
        "\t(Keeping Up With the Kardashians - Weekend From Hell)\n",
        "[0.28] KHLOE: This is a stakeout.\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "[0.28] BRUCE: This is the stakeout?\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "\n",
        "####################################\n",
        "Your yapping is making my head ache!\n",
        "####################################\n",
        "[0.54] ADRIENNE: My stepdad is a marine.\n",
        "\t(Keeping Up With the Kardashians - Leaving the Nest)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0.50] KHLOE: My dignity and pride!\n",
        "\t(Keeping Up With the Kardashians - Kris the Cheerleader)\n",
        "[0.50] LAMAR: My brother-in-law!\n",
        "\t(Keeping Up With the Kardashians - Blind Date)\n",
        "[0.50] KIM: My shoe!\n",
        "\t(Keeping Up With the Kardashians - Hot Cup of Love)\n",
        "[0.50] KIM: My shoe!\n",
        "\t(Keeping Up With the Kardashians - Hot Cup of Love)\n",
        "[0.50] KIM: My shoe!\n",
        "\t(Keeping Up With the Kardashians - Hot Cup of Love)\n",
        "[0.44] KHLOE: This is my opinion.\n",
        "\t(Keeping Up With the Kardashians - Kim's Calendar for Reggie)\n",
        "[0.44] CARLA: This is my assistant, Tim.\n",
        "\t(Keeping Up With the Kardashians - Leaving the Nest)\n",
        "[0.44] SUSAN: Duff is just my hero.\n",
        "\t(Keeping Up With the Kardashians - The Kardashians Take NYC)\n",
        "[0.43] KHLOE: This is stunning!\n",
        "\t(Keeping Up With the Kardashians - What's Yours Is Mine)\n",
        "\n",
        "######################################\n",
        "I'm going to Maryland, did I tell you?\n",
        "######################################\n",
        "[0.54] BRUCE: Did I tell you I'm going to maryland?\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0.48] FRIEND: I'm going to .\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "[0.48] FRIEND: I'm going to .\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "[0.48] KOURTNEY: I'm going.\n",
        "\t(Keeping Up With the Kardashians - Kim Becomes a Diva)\n",
        "[0.48] KHLOE: I'm going to barf.\n",
        "\t(Keeping Up With the Kardashians - You Are So Pregnant Dude)\n",
        "[0.48] KIM: I'm going to doPlayboy.\n",
        "\t(Keeping Up With the Kardashians - I'm Watching You)\n",
        "[0.42] ROB: I'm going to tell her.\n",
        "\t(Keeping Up With the Kardashians - Meet the Kardashians)\n",
        "[0.40] TEACHER: So I'm going to demonstrate.\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "[0.39] BRUCE: I'm a puss.\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "[0.39] KOURTNEY: I'm Catherine.\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One problem is that the query words should have different weights.\n",
      "Another is that the max threshold is too high; it is still including relatively common words like 'is' and 'my'.\n",
      "\n",
      "Queries with words that are extremely not common, like 'Maryland' will work somewhat well wiht this method."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Find the most similar messages to the quotes in terms of Edit Distance\n",
      "\n",
      "This section is most easily solved using the [python-Levenshtein](https://github.com/ztane/python-Levenshtein) package.\n",
      "\n",
      "### Q6 Write an `edit_distance_search` function.\n",
      "\n",
      "This time, do not use a tokenizer, as we are looking for character-level edits of the quotes, to catch typos and variations.\n",
      "Run the search using the code provided. Discuss why it worked, or why it might not have worked, for each query."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _edit(query_str, msg):\n",
      "    return Levenshtein.distance(query_str.lower(), msg['text'].lower())\n",
      "\n",
      "\n",
      "def edit_distance_search(query, msgs):\n",
      "    \"\"\" Edit distance search\n",
      "    \n",
      "    Arguments\n",
      "    =========\n",
      "    \n",
      "    query: string,\n",
      "        The query we are looking for.\n",
      "        \n",
      "    msgs: list of dicts,\n",
      "        Each message in this list already has a 'toks'\n",
      "        field that contains the tokenized message.\n",
      "    \n",
      "    Returns\n",
      "    =======\n",
      "    \n",
      "    result: list of (score, message) tuples.\n",
      "        The result list is sorted by score such that the closest match\n",
      "        is the top result in the list.\n",
      "    \n",
      "    \"\"\"\n",
      "    \n",
      "    results = []\n",
      "    \n",
      "    for msg in msgs:\n",
      "        results.append( (_edit(query, msg), msg) )\n",
      "    \n",
      "    return sorted(results, key=lambda tup: tup[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for query in queries:\n",
      "    print(\"#\" * len(query))\n",
      "    print(query)\n",
      "    print(\"#\" * len(query))\n",
      "\n",
      "    for score, msg in edit_distance_search(query, flat_msgs)[:10]:\n",
      "        print(\"[{:.2f}] {}: {}\\n\\t({})\".format(\n",
      "            score,\n",
      "            msg['speaker'].encode('utf-8'),\n",
      "            msg['text'].encode('utf-8'),\n",
      "            msg['episode_title'].encode('utf-8')))\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#################################################################\n",
        "It's like a bunch of people running around talking about nothing.\n",
        "#################################################################\n",
        "[0.00] BRUCE: It's like a bunch of people running around talking about nothing.\n",
        "\t(Keeping Up With the Kardashians - Kourt's First Cover)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[33.00] KRIS: It's not a bunch of teenagers running around.\n",
        "\t(Keeping Up With the Kardashians - Kris ``The Cougar'' Jenner)\n",
        "[35.00] KHLOE: It's like, what are you talking about?\n",
        "\t(The Wedding: Keeping Up With the Kardashians)\n",
        "[37.00] KIM: It's like it has separation anxiety or something.\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "[37.00] KHLOE: It's like I want to learn how to do that.\n",
        "\t(Keeping Up With the Kardashians - Distance Makes the Heart Grow Fonder)\n",
        "[37.00] KOURTNEY: It's like an explosion in your pantyhose.\n",
        "\t(Keeping Up With the Kardashians - I'd Rather Go Naked... Or Shopping)\n",
        "[38.00] ROB: I have a bunch of connections in the industry.\n",
        "\t(Keeping Up With the Kardashians - Must Love Dogs)\n",
        "[38.00] ROB: I have a bunch of connections in the industry.\n",
        "\t(Keeping Up With the Kardashians - Must Love Dogs)\n",
        "[38.00] BRUCE: That's why you're running around wearing black.\n",
        "\t(Keeping Up With the Kardashians - I'd Rather Go Naked... Or Shopping)\n",
        "[38.00] BRUCE: That's why you're running around wearing black.\n",
        "\t(Keeping Up With the Kardashians - Kourt's First Cover)\n",
        "\n",
        "#############################################################################################\n",
        "Never say to a famous person that this possible endorsment would bring 'er to the spot light.\n",
        "#############################################################################################\n",
        "[42.00] SIMON: You don't tell an international celebrity that this possible endorsement could bring her back into the spotlight.\n",
        "\t(Keeping Up With the Kardashians - Delivering Baby Mason)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[59.00] KRIS: You need to trust that I actually know what I'm doing at some point.\n",
        "\t(Keeping Up With the Kardashians - Blame It on the Alcohol)\n",
        "[60.00] BRUCE: You know, I've seen her do this before, and it's just not right.\n",
        "\t(Keeping Up With the Kardashians - Baby Blues)\n",
        "[60.00] ALEX: I feel like people want to see you, like, back in the spotlight.\n",
        "\t(Keeping Up With the Kardashians - Delivering Baby Mason)\n",
        "[60.00] KHLOE: Trust me, this is the most entertaining part of the entire night.\n",
        "\t(Keeping Up With the Kardashians - Birthday Suit)\n",
        "[60.00] ROB: I clean all the counters at like from the floors to the bathtub to the toilet.\n",
        "\t(Keeping Up With the Kardashians - Kim's Calendar for Reggie)\n",
        "[60.00] KIM: I didn't want to go on this trip and I'm not talking to them at all.\n",
        "\t(Keeping Up With the Kardashians - Kardashian Civil War)\n",
        "[60.00] ELIZABETH: I reminded you this morning that you needed to bring the designs.\n",
        "\t(Keeping Up With the Kardashians - Family vs. Money)\n",
        "[60.00] KRIS: Okay. If it was you against the other three, I would have felt the same way.\n",
        "\t(Keeping Up With the Kardashians - Kardashian Civil War)\n",
        "[60.00] DAVID: We're gonna take a look at these Polaroids, and then we'll be right with you.\n",
        "\t(Keeping Up With the Kardashians - Khloe's Blind Dates)\n",
        "\n",
        "####################################\n",
        "Your yapping is making my head ache!\n",
        "####################################\n",
        "[15.00] KIM: Your yappity voice is giving me a headache!\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[15.00] KIM: Your yappity voice is giving me a headache!\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "[20.00] KIM: You want to make peace?\n",
        "\t(Keeping Up With the Kardashians - Family vs. Money)\n",
        "[21.00] BRUCE: Everything's going to be fine.\n",
        "\t(Keeping Up With the Kardashians - The Missing Ring)\n",
        "[21.00] KHLOE: You are walking me me down...\n",
        "\t(Keeping Up With the Kardashians - The Wedding)\n",
        "[21.00] KHLOE: You are walking me me down...\n",
        "\t(The Wedding: Keeping Up With the Kardashians)\n",
        "[21.00] KRIS: You're going to make a scene.\n",
        "\t(Keeping Up With the Kardashians - What's Yours Is Mine)\n",
        "[22.00] BRUCE: You're diving in for the cash?\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "[22.00] KHLOE: Your secret is safe with me.\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "[22.00] BRUCE: You're diving in for   the  cash?\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "\n",
        "######################################\n",
        "I'm going to Maryland, did I tell you?\n",
        "######################################\n",
        "[18.00] LAMAR: I'm going to go play with Rob.\n",
        "\t(Keeping Up With the Kardashians - Blind Date)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[19.00] KHLOE: I'm going to move to New York.\n",
        "\t(Keeping Up With the Kardashians - Distance Makes the Heart Grow Fonder)\n",
        "[19.00] SCOTT: I'm going to have six or seven?\n",
        "\t(Keeping Up With the Kardashians - The Wedding)\n",
        "[19.00] KHLOE: I'm going to move to New York.\n",
        "\t(Keeping Up With the Kardashians - Free Khloe)\n",
        "[19.00] SCOTT: I'm going to have six or seven?\n",
        "\t(The Wedding: Keeping Up With the Kardashians)\n",
        "[19.00] KRIS: I'm going to lunch with Lisa.\n",
        "\t(The Wedding: Keeping Up With the Kardashians)\n",
        "[20.00] FRIEND: I'm going to get canned inside.\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "[20.00] FRIEND: I'm going to get canned inside.\n",
        "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
        "[20.00] ROB: I'm going to tell her.\n",
        "\t(Keeping Up With the Kardashians - Meet the Kardashians)\n",
        "[20.00] LAMAR: I'm going to need it.\n",
        "\t(Keeping Up With the Kardashians - I Want Your Sex)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Edit distance produced overall better results because it matched the sentence structure. \n",
      "\n",
      "However, for common sentence parts, like \"I'm going to\" in the Maryland query, it returns irrelavent results because lots of sentences match thsi part if query."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Q7 Print the changes that need to be done to each quote to make it look like the closest match.\n",
      "\n",
      "Most of the code needed is provided below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = \"kardashians\"\n",
      "b = \"dalmatians\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_edits(str_a, str_b, edits):\n",
      "    output = [[char] for char in str_a]\n",
      "    indices = np.arange(len(str_a) + 1)\n",
      "    for op, src, dest in edits:\n",
      "        if op == 'insert':\n",
      "            src = indices[src]\n",
      "            output.insert(src, [\"<span class='add'>{}</span>\".format(str_b[dest])])\n",
      "            indices += 1\n",
      "        elif op == 'replace':\n",
      "            src = indices[src]\n",
      "            src_char = output[src][0]\n",
      "            output[src] = output[src][1:]\n",
      "            output[src].append(\"<span class='del'>{}</span><span class='add'>{}</span>\".format(src_char, str_b[dest]))\n",
      "        elif op == 'delete':\n",
      "            src = indices[src]\n",
      "            src_char = output[src].pop()\n",
      "            output[src].append(\"<span class='del'>{}</span>\".format(src_char))\n",
      "    \n",
      "    return \"<div class='edit'>{}</div>\".format(\"\".join(\"\".join(stack) for stack in output))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML(\"\"\"\n",
      "<style type=\"text/css\">\n",
      "\n",
      ".edit {font-size: 20px;}\n",
      ".del {text-decoration: line-through; color: #aaa;}\n",
      ".add {color: green; font-weight: bold;}\n",
      "</style>\n",
      "\"\"\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "<style type=\"text/css\">\n",
        "\n",
        ".edit {font-size: 20px;}\n",
        ".del {text-decoration: line-through; color: #aaa;}\n",
        ".add {color: green; font-weight: bold;}\n",
        "</style>\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "<IPython.core.display.HTML at 0xf69416c>"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_query(query):\n",
      "    best_match = unicode(edit_distance_search(query, flat_msgs)[0])\n",
      "    \n",
      "    edits = Levenshtein.editops(query, best_match)\n",
      "    HTML(print_edits(query, best_match, edits))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "query = queries[0]\n",
      "\n",
      "print(edit_distance_search(query, flat_msgs)[0]['text'])\n",
      "    \n",
      "#edits = Levenshtein.editops(query, best_match)\n",
      "#HTML(print_edits(query, best_match, edits))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "tuple indices must be integers, not str",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-91-662f52dd9f87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medit_distance_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_msgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#edits = Levenshtein.editops(query, best_match)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers, not str"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Bonus question for extra course credit.\n",
      "\n",
      "### Updating precomputed values.\n",
      "\n",
      "In many real-world applications, the collection of documents will not stay the same forever. At Internet-scale, however, it could possibly even be worth recomputing things every second, if during that second we're going to answer millions of queries.\n",
      "\n",
      "However, there's a better way: in reality, the document set will not change radically, but incrementally.  In particular, it's most common to add or remove a bunch of new documents to the index.\n",
      "\n",
      "Write functions `add_docs` and `remove_docs` that update the index, idf and document norms.  Think of the implications this has on how we store the IDF. Is there a better way of storing it, that minimizes the memory we need to touch when updating?\n",
      "\n",
      "Think of adequate test cases for these functions and implement them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}